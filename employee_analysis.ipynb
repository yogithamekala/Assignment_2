{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tweepy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtweepy\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tweepy'"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Key setup\n",
    "api_key = 'XLrT4TY4C8ZdIFQOMri1QX6Cc'\n",
    "api_secret_key = 'nFdnp9YT30Omojj9JZdtqD6j6qKP6vvuo65FjLOt6Fe0eotwpZ'\n",
    "access_token = '3083368926-c7fXpsH0k1Hrqs6bNe7954RMMp7viwgK7paRuHX'\n",
    "access_token_secret = 'bTTr0tiF4Xizcnjj7gGS1efzhSN5Co8Cgcc0P1cHjMXeF'\n",
    "# Bearer token from Twitter API v2\n",
    "bearer_token = 'AAAAAAAAAAAAAAAAAAAAAJttvwEAAAAAve3ZMFPG3IVh5poNuakDQUxLo%2Fw%3DcdUn78VL26nE15hTVzu9hjKEl1raNd8xRnvL00uVVloJABXMSD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate to Twitter\n",
    "auth = tweepy.OAuthHandler(api_key, api_secret_key)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Timestamp            Author_ID  \\\n",
      "0 2024-09-18 18:45:55+00:00            967002391   \n",
      "1 2024-09-18 18:45:46+00:00  1739969421421031424   \n",
      "2 2024-09-18 18:45:45+00:00  1196436451463966722   \n",
      "3 2024-09-18 18:45:16+00:00            322010071   \n",
      "4 2024-09-18 18:44:01+00:00   840985196195434498   \n",
      "\n",
      "                                               Tweet  \n",
      "0  RT @thugsprayers: Being called “EFF” or “Malem...  \n",
      "1  RT @thugsprayers: Being called “EFF” or “Malem...  \n",
      "2  RT @thugsprayers: Being called “EFF” or “Malem...  \n",
      "3  RT @thugsprayers: Being called “EFF” or “Malem...  \n",
      "4  RT @NWCI: \"The gender disparity suggests that ...  \n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import logging\n",
    "\n",
    "# Create client for Twitter API v2\n",
    "client = tweepy.Client(bearer_token=bearer_token)\n",
    "\n",
    "# Query tweets using the v2 API\n",
    "query = 'attrition risk OR employee turnover OR workplace stress OR HR issues lang:en'\n",
    "response = client.search_recent_tweets(query=query, tweet_fields=['created_at', 'author_id', 'text'], max_results=100)\n",
    "\n",
    "# Store tweet details in a DataFrame\n",
    "tweet_data = []\n",
    "for tweet in response.data:\n",
    "    tweet_data.append([tweet.created_at, tweet.author_id, tweet.text])\n",
    "\n",
    "df_tweets = pd.DataFrame(tweet_data, columns=['Timestamp', 'Author_ID', 'Tweet'])\n",
    "\n",
    "# Display first few rows\n",
    "print(df_tweets.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Tweet  \\\n",
      "0  RT @thugsprayers: Being called “EFF” or “Malem...   \n",
      "1  RT @thugsprayers: Being called “EFF” or “Malem...   \n",
      "2  RT @thugsprayers: Being called “EFF” or “Malem...   \n",
      "3  RT @thugsprayers: Being called “EFF” or “Malem...   \n",
      "4  RT @NWCI: \"The gender disparity suggests that ...   \n",
      "\n",
      "                                       Cleaned_Tweet  \n",
      "0  rt  being called eff or malema for speaking ou...  \n",
      "1  rt  being called eff or malema for speaking ou...  \n",
      "2  rt  being called eff or malema for speaking ou...  \n",
      "3  rt  being called eff or malema for speaking ou...  \n",
      "4  rt  the gender disparity suggests that women m...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_tweet(text):\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text)     # Remove mentions\n",
    "    text = re.sub(r'#', '', text)        # Remove hashtags\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)  # Remove special characters\n",
    "    return text.strip().lower()\n",
    "\n",
    "df_tweets['Cleaned_Tweet'] = df_tweets['Tweet'].apply(clean_tweet)\n",
    "print(df_tweets[['Tweet', 'Cleaned_Tweet']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Cleaned_Tweet Sentiment\n",
      "0  rt  being called eff or malema for speaking ou...  NEGATIVE\n",
      "1  rt  being called eff or malema for speaking ou...  NEGATIVE\n",
      "2  rt  being called eff or malema for speaking ou...  NEGATIVE\n",
      "3  rt  being called eff or malema for speaking ou...  NEGATIVE\n",
      "4  rt  the gender disparity suggests that women m...  NEGATIVE\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load sentiment-analysis pipeline\n",
    "sentiment_model = pipeline('sentiment-analysis')\n",
    "\n",
    "# Apply sentiment analysis\n",
    "df_tweets['Sentiment'] = df_tweets['Cleaned_Tweet'].apply(lambda tweet: sentiment_model(tweet)[0]['label'])\n",
    "\n",
    "print(df_tweets[['Cleaned_Tweet', 'Sentiment']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_20640\\472202984.py:9: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values, palette='viridis')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Count the sentiment occurrences\n",
    "sentiment_counts = df_tweets['Sentiment'].value_counts()\n",
    "\n",
    "# Plot the sentiment distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values, palette='viridis')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Sentiment Distribution of Tweets')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=500)\n",
    "X = vectorizer.fit_transform(df_tweets['Cleaned_Tweet'])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_features = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.97      1.00      0.98        29\n",
      "    POSITIVE       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.48      0.50      0.49        30\n",
      "weighted avg       0.93      0.97      0.95        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming you have labels for training\n",
    "y = df_tweets['Sentiment'] \n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a Random Forest model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Fetch time: 0.44 seconds\n",
      "INFO:root:Process time: 0.00 seconds\n",
      "INFO:root:Feature extraction time: 0.00 seconds\n",
      "INFO:root:Prediction time: 0.01 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: RT @thugsprayers: Being called “EFF” or “Malema” for speaking out on issues that are concerning in my work place, surely calls for HR, no?\n",
      "Prediction: NEGATIVE\n",
      "\n",
      "Tweet: RT @thugsprayers: Being called “EFF” or “Malema” for speaking out on issues that are concerning in my work place, surely calls for HR, no?\n",
      "Prediction: NEGATIVE\n",
      "\n",
      "Tweet: RT @thugsprayers: Being called “EFF” or “Malema” for speaking out on issues that are concerning in my work place, surely calls for HR, no?\n",
      "Prediction: NEGATIVE\n",
      "\n",
      "Tweet: RT @thugsprayers: Being called “EFF” or “Malema” for speaking out on issues that are concerning in my work place, surely calls for HR, no?\n",
      "Prediction: NEGATIVE\n",
      "\n",
      "Tweet: RT @NWCI: \"The gender disparity suggests that women may be disproportionately affected by stressors in the workplace and beyond\"\n",
      "\n",
      "#Childcar…\n",
      "Prediction: NEGATIVE\n",
      "\n",
      "Processed 5 tweets. Exiting...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "def process_tweets():\n",
    "    tweet_count = 0\n",
    "    max_tweets = 5\n",
    "    \n",
    "    while tweet_count < max_tweets:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # Fetch new tweets\n",
    "            fetch_start = time.time()\n",
    "            response = client.search_recent_tweets(query=query, tweet_fields=['created_at', 'author_id', 'text'], max_results=10)\n",
    "            if response.data is None:\n",
    "                logger.warning(\"No tweets found.\")\n",
    "                time.sleep(60)  # Sleep and retry if no tweets\n",
    "                continue\n",
    "            fetch_time = time.time() - fetch_start\n",
    "            \n",
    "            # Process and clean tweets\n",
    "            process_start = time.time()\n",
    "            new_tweets = pd.DataFrame([[tweet.created_at, tweet.author_id, tweet.text] for tweet in response.data], columns=['Timestamp', 'Author_ID', 'Tweet'])\n",
    "            new_tweets['Cleaned_Tweet'] = new_tweets['Tweet'].apply(clean_tweet)\n",
    "            process_time = time.time() - process_start\n",
    "            \n",
    "            # Extract features\n",
    "            feature_start = time.time()\n",
    "            new_features = vectorizer.transform(new_tweets['Cleaned_Tweet'])\n",
    "            df_new_features = pd.DataFrame(new_features.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "            feature_time = time.time() - feature_start\n",
    "            \n",
    "            # Predict attrition risk\n",
    "            predict_start = time.time()\n",
    "            predictions = model.predict(df_new_features)\n",
    "            predict_time = time.time() - predict_start\n",
    "            \n",
    "            # Output predictions and increment tweet_count\n",
    "            for tweet, prediction in zip(new_tweets['Tweet'], predictions):\n",
    "                if tweet_count < max_tweets:\n",
    "                    print(f\"Tweet: {tweet}\\nPrediction: {prediction}\\n\")\n",
    "                    tweet_count += 1\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "            # Log times\n",
    "            logger.info(f\"Fetch time: {fetch_time:.2f} seconds\")\n",
    "            logger.info(f\"Process time: {process_time:.2f} seconds\")\n",
    "            logger.info(f\"Feature extraction time: {feature_time:.2f} seconds\")\n",
    "            logger.info(f\"Prediction time: {predict_time:.2f} seconds\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"An error occurred: {e}\")\n",
    "            break\n",
    "        \n",
    "        if tweet_count < max_tweets:\n",
    "            # Sleep for a while before fetching new tweets\n",
    "            time.sleep(60)  # Fetch new tweets every 1 minute\n",
    "    \n",
    "    print(\"Processed 5 tweets. Exiting...\")\n",
    "\n",
    "# Run the real-time processing function\n",
    "process_tweets()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying LLM --> GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the sentiment-analysis pipeline\n",
    "sentiment_model = pipeline('sentiment-analysis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Cleaned_Tweet LLM_Sentiment\n",
      "0  rt  being called eff or malema for speaking ou...      NEGATIVE\n",
      "1  rt  being called eff or malema for speaking ou...      NEGATIVE\n",
      "2  rt  being called eff or malema for speaking ou...      NEGATIVE\n",
      "3  rt  being called eff or malema for speaking ou...      NEGATIVE\n",
      "4  rt  the gender disparity suggests that women m...      NEGATIVE\n"
     ]
    }
   ],
   "source": [
    "# Apply sentiment analysis using the LLM\n",
    "df_tweets['LLM_Sentiment'] = df_tweets['Cleaned_Tweet'].apply(lambda tweet: sentiment_model(tweet)[0]['label'])\n",
    "\n",
    "print(df_tweets[['Cleaned_Tweet', 'LLM_Sentiment']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Initialize GPT-2 model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Cleaned_Tweet  \\\n",
      "0  rt  being called eff or malema for speaking ou...   \n",
      "1  rt  being called eff or malema for speaking ou...   \n",
      "2  rt  being called eff or malema for speaking ou...   \n",
      "3  rt  being called eff or malema for speaking ou...   \n",
      "4  rt  the gender disparity suggests that women m...   \n",
      "\n",
      "                                    Generated_Topics  \n",
      "0  rt  being called eff or malema for speaking ou...  \n",
      "1  rt  being called eff or malema for speaking ou...  \n",
      "2  rt  being called eff or malema for speaking ou...  \n",
      "3  rt  being called eff or malema for speaking ou...  \n",
      "4  rt  the gender disparity suggests that women m...  \n"
     ]
    }
   ],
   "source": [
    "def generate_topics(text, max_input_length=50, max_new_tokens=20):\n",
    "    # Truncate the input text if it's longer than the max_input_length\n",
    "    inputs = tokenizer.encode(text[:max_input_length], return_tensors='pt')\n",
    "    \n",
    "    # Generate topics with a set number of new tokens\n",
    "    outputs = model.generate(inputs, max_new_tokens=max_new_tokens, num_return_sequences=1)\n",
    "    \n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Apply topic generation to the cleaned tweets\n",
    "df_tweets['Generated_Topics'] = df_tweets['Cleaned_Tweet'].apply(generate_topics)\n",
    "\n",
    "# Display the results\n",
    "print(df_tweets[['Cleaned_Tweet', 'Generated_Topics']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: RT @thugsprayers: Being called “EFF” or “Malema” for speaking out on issues that are concerning in my work place, surely calls for HR, no?\n",
      "LLM Sentiment: NEGATIVE\n",
      "\n",
      "Tweet: RT @thugsprayers: Being called “EFF” or “Malema” for speaking out on issues that are concerning in my work place, surely calls for HR, no?\n",
      "LLM Sentiment: NEGATIVE\n",
      "\n",
      "Tweet: RT @thugsprayers: Being called “EFF” or “Malema” for speaking out on issues that are concerning in my work place, surely calls for HR, no?\n",
      "LLM Sentiment: NEGATIVE\n",
      "\n",
      "Tweet: RT @thugsprayers: Being called “EFF” or “Malema” for speaking out on issues that are concerning in my work place, surely calls for HR, no?\n",
      "LLM Sentiment: NEGATIVE\n",
      "\n",
      "Tweet: RT @thugsprayers: Being called “EFF” or “Malema” for speaking out on issues that are concerning in my work place, surely calls for HR, no?\n",
      "LLM Sentiment: NEGATIVE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def process_tweets_with_llm():\n",
    "    tweet_count = 0  # Counter for the number of tweets processed\n",
    "    \n",
    "    while tweet_count < 5:  # Loop until 5 tweets are processed\n",
    "        # Fetch new tweets\n",
    "        response = client.search_recent_tweets(query=query, tweet_fields=['created_at', 'author_id', 'text'], max_results=10)\n",
    "        \n",
    "        # Process and clean tweets\n",
    "        new_tweets = pd.DataFrame([[tweet.created_at, tweet.author_id, tweet.text] for tweet in response.data], columns=['Timestamp', 'Author_ID', 'Tweet'])\n",
    "        new_tweets['Cleaned_Tweet'] = new_tweets['Tweet'].apply(clean_tweet)\n",
    "        \n",
    "        # Apply LLM sentiment analysis\n",
    "        new_tweets['LLM_Sentiment'] = new_tweets['Cleaned_Tweet'].apply(lambda tweet: sentiment_model(tweet)[0]['label'])\n",
    "        \n",
    "        # Output results\n",
    "        for tweet, sentiment in zip(new_tweets['Tweet'], new_tweets['LLM_Sentiment']):\n",
    "            print(f\"Tweet: {tweet}\\nLLM Sentiment: {sentiment}\\n\")\n",
    "            tweet_count += 1\n",
    "            if tweet_count >= 5:\n",
    "                break\n",
    "        \n",
    "        # If 5 tweets have been printed, exit the loop\n",
    "        if tweet_count >= 5:\n",
    "            break\n",
    "\n",
    "# Run the real-time processing function with LLM\n",
    "process_tweets_with_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Define test paths\n",
    "test_tokenizer_path = r'C:\\temp\\tokenizer'\n",
    "test_model_path = r'C:\\temp\\model'\n",
    "\n",
    "# Create test directories\n",
    "os.makedirs(test_tokenizer_path, exist_ok=True)\n",
    "os.makedirs(test_model_path, exist_ok=True)\n",
    "\n",
    "# Save the tokenizer and model to the test directories\n",
    "tokenizer.save_pretrained(test_tokenizer_path)\n",
    "model.save_pretrained(test_model_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
